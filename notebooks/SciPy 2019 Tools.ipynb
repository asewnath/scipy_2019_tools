{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy 2019 Tools Overview\n",
    "\n",
    "## This notebook is an overview of tools mentioned in the SciPy 2019 Conference.\n",
    "By Akira Sewnath\n",
    "\n",
    "These tools are mostly for data science and data visualization. More information about some of these packages can be found at [www.scipy2019.scipy.org/tutorial-participant-instructions](https://www.scipy2019.scipy.org/tutorial-participant-instructions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SatPy\n",
    "\n",
    "A package originally designed for quickly generating high quality, high resolution satellite imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data files\n",
    "\n",
    "SatPy centers around the class \"Scene\". Data is loaded into a Scene via one of the readers available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from satpy import Scene\n",
    "from glob import glob\n",
    "\n",
    "# Get the list of GOES-16 ABI files to open\n",
    "filenames = glob('../data/abi_l1b/20180511_texas_fire_abi_l1b_conus/*.nc')\n",
    "#filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out available readers\n",
    "from satpy import available_readers\n",
    "sorted(available_readers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn = Scene(reader='abi_l1b', filenames=filenames)\n",
    "scn.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files aren't actually loaded into scene until you explicitly load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.available_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Scene` is telling us that we have all 16 ABI channels available to load. This list includes any product that we can load from the file that the \"abi_l1b\" reader is configured to access. If we didn't provide all of the necessary files or the data was missing from the file for some reason, that product would not be listed here.\n",
    "\n",
    "| Channel     | Wavelength  |  Resolution  |\n",
    "| ----------- | ----------- |  ----------- |\n",
    "| C01         | 0.47µm      |  1000m       |\n",
    "| C02         | 0.64µm      |  250m        |\n",
    "| C03         | 0.64µm      |  1000m       |\n",
    "| C04         | 1.37µm      |  2000m       |\n",
    "| C05         | 1.60µm      |  1000m       |\n",
    "| C06         | 2.20µm      |  2000m       |\n",
    "| C07         | 3.90µm      |  2000m       |\n",
    "| C08         | 6.20µm      |  2000m       |\n",
    "| C09         | 6.90µm      |  2000m       |\n",
    "| C10         | 7.30µm      |  2000m       |\n",
    "| C11         | 8.40µm      |  2000m       |\n",
    "| C12         | 9.60µm      |  2000m       |\n",
    "| C13         | 10.30µm     |  2000m       |\n",
    "| C14         | 11.20µm     |  2000m       |\n",
    "| C15         | 12.30µm     |  2000m       |\n",
    "| C16         | 13.30µm     |  2000m       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_channel = 'C01'\n",
    "scn.load([my_channel])\n",
    "scn[my_channel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../pictures/dask.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(scn[my_channel])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from satpy import available_writers\n",
    "sorted(available_writers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "  scn.save_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SatPy provides methods for resampling channels for comparison purposes or to change projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scn.load(['C05'])\n",
    "scn['C05'].attrs['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scn.load(['C06'])\n",
    "scn['C06'].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The native resampler used has two possible operations:\n",
    "\n",
    "1. If remapping data to a higher resolution, replicate each pixel to make the shape matches.\n",
    "2. If remapping data to a lower resolution, average/aggregate the pixels to make the shapes match.\n",
    "\n",
    "By default this resamples to the highest resolution area (smallest footprint per pixel) shared between the loaded datasets. You can easily specify the lower resolution by adding the argument `scn.min_area()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_scn = scn.resample(resampler='native')\n",
    "new_scn['C05'].shape == new_scn['C06'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scn['C06'].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scn.available_composite_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use the `airmass` preconfigured compsite. The airmass RGB is made of the following bands:\n",
    "\n",
    "- R: C08 - C10\n",
    "- G: C12 - C13\n",
    "- B: C08\n",
    "\n",
    "The red channel is the difference between the C08 (6.185µm) and C10 (7.34µm) bands, the green channel is the difference between the C12 (9.61µm) and C13 (10.35µm) bands, and the blue channel is the C08 (6.185µm) band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.load(['airmass'])\n",
    "scn['airmass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy.writers import get_enhanced_image\n",
    "\n",
    "plt.figure()\n",
    "img = get_enhanced_image(scn['airmass'])\n",
    "img_data = img.data\n",
    "img_data.plot.imshow(rgb='bands', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopandas\n",
    "\n",
    "Extends pandas to create tools specifically for geospatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data\n",
    "\n",
    "Explicitly creating geodata from flat text files. Data from [insideairbnb.com](https://insideairbnb.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas\n",
    "neighborhoods = pandas.read_csv('../data/neighborhoods.csv')\n",
    "listings = pandas.read_csv('../data/listings.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first dataset, the `listings` data, records are provided with information about the latitude and longitude of the listing. You can use the latitude and longitude data to construct geometries required to create a `geodataframe`, a subclass of `pandas` dataframe useful for working with geographic data, directly from coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(listings.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other dataset contains information about different regions in the Austin area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*wkb*: well known binary representation of geographical information. Often, the well-known binary representation is a string of binary digits, encoded in hexidecimal, that represents the structure of the geometry corresponding to that record in the dataframe. Neighborhoods are \"areal\" features, meaning that they are polygons. Thus, the well-known binary column encodes the shape of these polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Geometries from Raw Coordinates\n",
    "\n",
    "Now we will turn both datasets into *geodataframes*. For the first dataset, `geopandas` has helper functions to construct a `geodataframe`. The `geodataframe` requires a `geoseries` called `geometry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries = geopandas.points_from_xy(listings.longitude, listings.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings = geopandas.GeoDataFrame(listings, geometry=geometries)\n",
    "listings['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a `geodataframe` for the neighborhoods dataset also requires us to explicitly define a `geometry`. This is done by reading in the wkb data using `shapely`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shapely import wkb\n",
    "neighborhoods['geometry'] = neighborhoods.wkb.apply(lambda shape: wkb.loads(shape, hex=True))\n",
    "neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.geometry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = geopandas.GeoDataFrame(neighborhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using basemap and contextily to create an image of the neighborhoods and AirBnB distributions. The coordinate reference system is set to the mercator projection for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neighborhoods.crs = {'init': 'epsg:3857'}\n",
    "#listings.crs = {'init':'epsg:3857'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neighborhoods.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import contextily\n",
    "#basemap, _ = contextily.bounds2img(*neighborhoods.total_bounds, zoom=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "neighborhoods.boundary.plot(ax=plt.gca(), color='orangered')\n",
    "listings.plot(ax=plt.gca(), marker='.', markersize=5, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "\n",
    "Seaborne is a statistical visualization package in Python meant to quickly create attractive graphs.\n",
    "\n",
    "<img src=\"../pictures/seaborn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as lp\n",
    "import numpy\n",
    "import contextily\n",
    "import shapely.geometry as geom\n",
    "import mapclassify\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geopandas.read_file('../data/neighborhoods.gpkg')\n",
    "listings = geopandas.read_file('../data/listings.gpkg')\n",
    "#preprocessing price\n",
    "listings['price'] = listings.price.str.replace('$', '').str.replace(',','_').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to aggregate the data within neighborhoods to look at median prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_price = geopandas.sjoin(listings[['price', 'geometry']], df, op='within')\\\n",
    "                  .groupby('index_right').price.median()\n",
    "df['median_pri'] = median_price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['median_pri'].fillna((df['median_pri'].mean()), inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "sbn.distplot(df['median_pri'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEODataFrame Chloropleth\n",
    "\n",
    "`geodataframe` has a default chloropleth graph for spatially defined attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot(column='median_pri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package to access geospatial raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "nightlight_file = rasterio.open('../data/txlights.tif')\n",
    "nightlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading bands into array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightlights = nightlight_file.read(1)\n",
    "nightlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(nightlights, cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue Data Visualization\n",
    "\n",
    "Glue is a GUI meant to aid data exploration through visualization tools. We're starting by loading the Iris dataset from [archive.uci.edu](https://archive.ics.uci.edu/ml/datasets.php). The data needed a little bit of preprocessing in order to create class subsets within Glue (changed class from string to integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('../data/iris.data', sep=\" \", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a couple screen shots when the Iris data is in Glue. You can select different subsets and view them in different plots to get a better understanding of your data's characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../pictures/glue_3d_scatter.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../pictures/glue_multiple_windows.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
